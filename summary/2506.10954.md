### 📄 最终论文总结

**Automating GitHub Issue Resolution Benchmark Construction with SWE-Factory**  
**基于SWE-Factory的GitHub问题解决基准自动化构建**

---

#### 1️⃣ 一句话总结

该论文提出了**SWE-Factory**自动化框架，通过多智能体协作（SWE-Builder）、标准化退出码评分和自动化fail2pass验证，解决了构建GitHub问题解决基准数据集的高人工成本问题，实验证明其显著提升了效率（单例成本$0.045）和准确性（测试结果检测100%准确率），并首次揭示了需过滤的**error2pass现象**。

---

#### 2️⃣ 论文创新点

- **全自动化流水线SWE-Factory**  
  整合环境构建、评分、验证三阶段，替代传统人工密集型流程（如RepoLaunch需手动解析日志），构建成本降低90%以上。  
  *意义：首次实现多语言/多仓库GitHub问题解决基准的端到端自动化。*

- **多智能体协作框架SWE-Builder**  
  通过四个专用智能体（如Repository Explorer提取依赖、Test Analyst迭代优化）模拟人工流程，环境构建成功率40.1%，支持跨项目差异处理。  
  *意义：通过分工协作和记忆池复用（如Dockerfile历史配置），显著提升效率与一致性。*

- **基于退出码的标准化评估**  
  利用测试框架退出码（0/非0）统一判定结果，替代定制化日志解析，实验验证100%准确率。  
  *意义：简化流程并提升鲁棒性，支持主流测试框架（如Python/TypeScript）。*

- **自动化fail2pass验证与error2pass过滤**  
  基于退出码实现高精度（0.92）验证，同时识别需排除的error2pass案例（如因依赖缺失导致的假通过）。  
  *意义：避免低估模型能力，提升基准质量。*

---

#### 3️⃣ 主要结果与价值

* **实验结果亮点**  
  - 环境构建成功率40.1%，单任务实例成本仅$0.045（GPT-4.1-mini）。  
  - 退出码评分与人工评估一致率100%，fail2pass验证精度0.92、召回率1.00。  
  - 构建数据集**SweSetupBench**（12个仓库）及其轻量版**SweSetupBench-lite**，覆盖多语言任务。  

* **实际应用价值**  
  - **开源社区**：为GitHub问题解决模型（如SWE-bench）提供高质量自动化评估基准。  
  - **工业部署**：低成本、可复现的环境构建方案，适用于企业级代码库测试。  
  - **研究指导**：提出的error2pass现象为未来基准设计提供关键筛选标准。  

---

#### 4️⃣ 术语表

* **SWE-Factory**：自动化GitHub问题解决基准构建流水线，含环境构建、评分、验证三组件。  
* **SWE-Builder**：多智能体框架（4个智能体），用于自动化评估环境构建与迭代优化。  
* **fail2pass**：测试用例从失败到通过的验证过程，核心基准质量指标。  
* **error2pass**：因前置错误（如依赖缺失）导致测试无法运行的现象，需过滤。  
* **exit code**：测试脚本返回的状态码（0成功/非0失败），用于标准化评估。  
* **SweSetupBench**：论文构建的多语言GitHub问题解决数据集（含轻量版SweSetupBench-lite）。