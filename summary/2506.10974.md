### 📄 最终论文总结

**论文的中英文题目**  
AUTOMIND: Adaptive Knowledge-Driven LLM Agent for Automated Data Science Tasks

---

#### 1️⃣ 一句话总结  
论文提出 **AUTOMIND**，一种结合专家知识库、树搜索算法和自适应编码策略的LLM代理框架，显著提升了数据科学任务的自动化效率（300%效率提升，63% token成本降低），并在MLE-Bench和Top AI竞赛中超越SOTA方法。

---

#### 2️⃣ 论文创新点  
- **专家知识库构建**：  
  从Kaggle竞赛方案和顶级论文中提取结构化知识，弥补LLM静态预训练的不足，提升任务解决有效性（Beats指标提升5.0%）。  
  *区别*：传统方法依赖纯数据驱动，而AUTOMIND整合人类经验。  
- **代理知识树搜索算法**：  
  将解决方案建模为树结构，支持动态调试、改进和生成操作，结合贪心与随机探索策略避免局部最优。  
  *改进*：相比线性搜索，树搜索更高效（时间效率提升3倍）。  
- **自适应编码策略**：  
  根据LLM评分动态选择单步或分步代码生成，降低错误累积（Beats指标提升24.6%）。  
  *意义*：平衡复杂任务与生成效率。  
- **轻量化评估基准（MLE-Bench Lite）**：  
  通过任务分级（Easy/Medium/Hard）和动态扩展（如2024竞赛任务），减少预训练数据泄露的评估偏差。  

---

#### 3️⃣ 主要结果与价值  
* **实验结果亮点**：  
  - 在MLE-Bench上超越AIDE等基线，Hard任务提升显著（Beats指标+30%）。  
  - 6小时内达到AIDE 24小时的性能，token成本降低63%。  
  - 消融实验验证专家知识库（+5% Beats）和自适应编码（+24.6% Beats）的关键作用。  

* **实际应用价值**：  
  - **自动化数据科学**：可部署于Kaggle竞赛、工业级数据建模等场景，减少人工干预。  
  - **跨领域扩展**：框架设计（知识库+树搜索）可迁移至科学发现、软件工程等领域。  
  - **资源高效性**：适合资源受限环境（如单GPU），支持大规模任务。  

---

#### 4️⃣ 术语表  
- **AUTOMIND**：自适应知识驱动的LLM代理框架，整合专家知识库与树搜索算法。  
- **LLM (Large Language Model)**：驱动代理的核心技术，如GPT系列模型。  
- **MLE-Bench**：轻量化评估基准，含75个Kaggle任务，分Easy/Medium/Hard三级。  
- **Beats (%)**：核心指标，表示超越人类参与者的比例。  
- **Solution Tree**：树状解决方案空间，节点含计划、代码、评估指标等。  
- **Self-Adaptive Coding**：动态选择单步/分步代码生成的策略。  
- **SELA**：对比方法之一，树搜索增强的LLM代理框架。  

--- 

总结归纳了框架设计、实验优势及跨领域潜力，术语表覆盖核心概念。