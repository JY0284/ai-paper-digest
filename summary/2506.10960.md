### 📄 最终论文总结

**论文的中英文题目**  
ChineseHarm-Bench: A Knowledge-Enhanced Benchmark for Chinese Harmful Content Detection  

---

#### 1️⃣ 一句话总结  
该论文提出了**ChineseHarm-Bench**，一个专注于中文有害内容检测的多类别基准数据集，结合知识规则库和知识增强方法，显著提升了轻量级模型的检测性能，填补了中文领域动态对抗性有害内容检测的空白。

---

#### 2️⃣ 论文创新点  
- **多类别中文有害内容基准**：  
  构建覆盖赌博、色情、辱骂等六类真实场景的专业标注数据集，解决现有资源（如COLD）在广度和语言针对性上的不足。  
- **动态知识规则库**：  
  通过标注过程同步生成显式规则库（*R_c*），兼具辅助人工标注和增强模型检测能力的双重作用，应对动态演化的规避策略（如拼音替换）。  
- **知识增强的小模型优化**：  
  提出混合知识提示（Hybrid Knowledgeable Prompting），结合显式规则与LLMs隐式知识，使轻量级模型（如Qwen-2.5-0.5B）Macro-F1从<0.5提升至>0.7，接近GPT-4o水平。  
- **合成数据生成方法**：  
  通过教师模型模拟用户规避行为生成对抗性数据，证明每类别3k样本即可饱和性能，且不同教师模型（如DeepSeek-R1）均有效。  

---

#### 3️⃣ 主要结果与价值  
* **实验结果亮点**  
  - 知识增强使1B以上参数模型Macro-F1平均提升20%，轻量级模型（0.5B）性能翻倍。  
  - 在包含规避策略的合成数据上，模型对拼音/同音词攻击的检测F1提高35%。  
  - 人工规则库+LLMs隐式知识的小模型（Qwen-2.5-1.5B）超越无知识增强的7B模型。  

* **实际应用价值**  
  - **资源效率**：为中文互联网平台提供低成本、高精度的内容审核方案，降低对大模型的依赖。  
  - **动态对抗**：通过规则库迭代更新应对新型规避策略（如表情符号滥用），提升长期有效性。  
  - **跨领域扩展**：方法论可迁移至其他语言或违规类型（如金融欺诈检测）。  

---

#### 4️⃣ 术语表  
* **ChineseHarm-Bench**：论文提出的六类中文有害内容检测基准数据集。  
* **LLMs (Large Language Models)**：如GPT-4o、Qwen-2.5，用于生成合成数据或作为教师模型。  
* **Hybrid Knowledgeable Prompting**：结合人物特征、规避策略和外部规则的结构化提示方法。  
* **Macro-F1**：多类别平衡评估指标，反映模型综合性能。  
* **SFT (Supervised Fine-Tuning)**：整合显式规则（*R*）和隐式知识（*A_i,c*）的训练框架。  
* **DeepSeek-R1**：用于生成合成数据的教师模型之一。  
* **Prompt_Detect**：零样本检测的标准化提示模板，嵌入法律规则知识。